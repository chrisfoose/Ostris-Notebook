{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Toolkit by Ostris\n",
        "## Slider Training\n",
        "\n",
        "This is a quick colab demo for training sliders like can be found in my CivitAI profile https://civitai.com/user/Ostris/models .  I will work on making it more user friendly, but for now, it will get you started."
      ],
      "metadata": {
        "collapsed": false,
        "id": "EXUuUfBbhdri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ostris/ai-toolkit"
      ],
      "metadata": {
        "id": "BvAG0GKAh59G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4ab567-3956-416d-b416-5c83be367934"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai-toolkit'...\n",
            "remote: Enumerating objects: 8517, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 8517 (delta 99), reused 57 (delta 55), pack-reused 8350 (from 3)\u001b[K\n",
            "Receiving objects: 100% (8517/8517), 32.01 MiB | 10.84 MiB/s, done.\n",
            "Resolving deltas: 100% (5945/5945), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGZqVER_aQJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1dbcd66-9a70-475c-874f-65dafc1eee75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/diffusers@8600b4c10d67b0ce200f664204358747bd53c775 (from -r requirements.txt (line 3))\n",
            "  Cloning https://github.com/huggingface/diffusers (to revision 8600b4c10d67b0ce200f664204358747bd53c775) to /tmp/pip-req-build-_ql1otxa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-_ql1otxa\n",
            "  Running command git rev-parse -q --verify 'sha^8600b4c10d67b0ce200f664204358747bd53c775'\n",
            "  Running command git fetch -q https://github.com/huggingface/diffusers 8600b4c10d67b0ce200f664204358747bd53c775\n",
            "  Running command git checkout -q 8600b4c10d67b0ce200f664204358747bd53c775\n",
            "  Resolved https://github.com/huggingface/diffusers to commit 8600b4c10d67b0ce200f664204358747bd53c775\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchao==0.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: transformers==4.57.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.57.3)\n",
            "Collecting lycoris-lora==1.8.3 (from -r requirements.txt (line 5))\n",
            "  Downloading lycoris_lora-1.8.3.tar.gz (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatten_json (from -r requirements.txt (line 6))\n",
            "  Downloading flatten_json-0.1.14-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (6.0.3)\n",
            "Collecting oyaml (from -r requirements.txt (line 8))\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.19.0)\n",
            "Collecting kornia (from -r requirements.txt (line 10))\n",
            "  Downloading kornia-0.8.2-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting invisible-watermark (from -r requirements.txt (line 11))\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.12.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.10.2)\n",
            "Collecting albumentations==1.4.15 (from -r requirements.txt (line 15))\n",
            "  Downloading albumentations-1.4.15-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting albucore==0.0.16 (from -r requirements.txt (line 16))\n",
            "  Downloading albucore-0.0.16-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (2.12.3)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (2.3.0)\n",
            "Collecting k-diffusion (from -r requirements.txt (line 19))\n",
            "  Downloading k_diffusion-0.1.1.post1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting open_clip_torch (from -r requirements.txt (line 20))\n",
            "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (1.0.24)\n",
            "Collecting prodigyopt (from -r requirements.txt (line 22))\n",
            "  Downloading prodigyopt-1.1.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting controlnet_aux==0.0.10 (from -r requirements.txt (line 23))\n",
            "  Downloading controlnet_aux-0.0.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (1.2.1)\n",
            "Collecting bitsandbytes (from -r requirements.txt (line 25))\n",
            "  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 26)) (0.1.9)\n",
            "Collecting lpips (from -r requirements.txt (line 27))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pytorch_fid (from -r requirements.txt (line 28))\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting optimum-quanto==0.2.4 (from -r requirements.txt (line 29))\n",
            "  Downloading optimum_quanto-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (0.2.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 31)) (0.36.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 32)) (0.18.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (5.50.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 34)) (8.0.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 35)) (4.12.0.88)\n",
            "Collecting pytorch-wavelets==1.3.0 (from -r requirements.txt (line 36))\n",
            "  Downloading pytorch_wavelets-1.3.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting matplotlib==3.10.1 (from -r requirements.txt (line 37))\n",
            "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting setuptools==69.5.1 (from -r requirements.txt (line 38))\n",
            "  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting scipy==1.12.0 (from -r requirements.txt (line 39))\n",
            "  Downloading scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av==16.0.1 (from -r requirements.txt (line 40))\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting torchcodec (from -r requirements.txt (line 41))\n",
            "  Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 4)) (3.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 4)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 4)) (0.22.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from lycoris-lora==1.8.3->-r requirements.txt (line 5)) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 15)) (0.25.2)\n",
            "Collecting eval-type-backport (from albumentations==1.4.15->-r requirements.txt (line 15))\n",
            "  Downloading eval_type_backport-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 15)) (4.12.0.88)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from controlnet_aux==0.0.10->-r requirements.txt (line 23)) (8.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from controlnet_aux==0.0.10->-r requirements.txt (line 23)) (11.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from controlnet_aux==0.0.10->-r requirements.txt (line 23)) (0.24.0+cu126)\n",
            "Collecting ninja (from optimum-quanto==0.2.4->-r requirements.txt (line 29))\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from pytorch-wavelets==1.3.0->-r requirements.txt (line 36)) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 37)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 37)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 37)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 37)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 37)) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.1->-r requirements.txt (line 37)) (2.9.0.post0)\n",
            "Collecting numpy>=1.17 (from transformers==4.57.3->-r requirements.txt (line 4))\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.37.0.dev0->-r requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.1.5)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia->-r requirements.txt (line 10))\n",
            "  Downloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from invisible-watermark->-r requirements.txt (line 11)) (1.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 13)) (5.9.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 17)) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 17)) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r requirements.txt (line 17)) (0.4.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->-r requirements.txt (line 18)) (4.9.3)\n",
            "Collecting clean-fid (from k-diffusion->-r requirements.txt (line 19))\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->-r requirements.txt (line 19))\n",
            "  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting dctorch (from k-diffusion->-r requirements.txt (line 19))\n",
            "  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n",
            "Collecting jsonmerge (from k-diffusion->-r requirements.txt (line 19))\n",
            "  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchdiffeq (from k-diffusion->-r requirements.txt (line 19))\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from k-diffusion->-r requirements.txt (line 19))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from k-diffusion->-r requirements.txt (line 19)) (0.23.1)\n",
            "Collecting ftfy (from open_clip_torch->-r requirements.txt (line 20))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r requirements.txt (line 31)) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r requirements.txt (line 31)) (1.2.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (3.11.5)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.0.21)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.14.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.21.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r requirements.txt (line 33)) (0.40.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio->-r requirements.txt (line 33)) (15.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.12/dist-packages (from python-slugify->-r requirements.txt (line 34)) (1.3)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python (from -r requirements.txt (line 35))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 33)) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio->-r requirements.txt (line 33)) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers==0.37.0.dev0->-r requirements.txt (line 3)) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers==0.37.0.dev0->-r requirements.txt (line 3)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->diffusers==0.37.0.dev0->-r requirements.txt (line 3)) (0.16.0)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless>=4.9.0.80 (from albumentations==1.4.15->-r requirements.txt (line 15))\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 33)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 33)) (2025.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 15)) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 15)) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 15)) (2025.12.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 15)) (0.4)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (1.14.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 33)) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 33)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 33)) (13.9.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 20)) (0.2.14)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->controlnet_aux==0.0.10->-r requirements.txt (line 23)) (3.23.0)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.12/dist-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 19)) (4.26.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.3->-r requirements.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.3->-r requirements.txt (line 4)) (2.5.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->-r requirements.txt (line 19))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 19)) (3.1.46)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 19)) (4.5.1)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 19)) (2.49.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 19)) (4.0.12)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 19)) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 19)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 19)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 19)) (0.30.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 33)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 33)) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 19)) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 33)) (0.1.2)\n",
            "Downloading albumentations-1.4.15-py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.16-py3-none-any.whl (9.5 kB)\n",
            "Downloading controlnet_aux-0.0.10-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum_quanto-0.2.4-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_wavelets-1.3.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n",
            "Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading kornia-0.8.2-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading k_diffusion-0.1.1.post1-py3-none-any.whl (33 kB)\n",
            "Downloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prodigyopt-1.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dctorch-0.1.2-py3-none-any.whl (2.3 kB)\n",
            "Downloading eval_type_backport-0.3.1-py3-none-any.whl (6.1 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n"
          ]
        }
      ],
      "source": [
        "!cd ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/ai-toolkit')\n",
        "from toolkit.job import run_job\n",
        "from collections import OrderedDict\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "wlcq3k5Rhdrn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "This is your config. It is documented pretty well. Normally you would do this as a yaml file, but for colab, this will work. This will run as is without modification, but feel free to edit as you want."
      ],
      "metadata": {
        "id": "N8UUFzVRigbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "job_to_run = OrderedDict({\n",
        "    # This is the config I use on my sliders, It is solid and tested\n",
        "    'job': 'train',\n",
        "    'config': {\n",
        "        # the name will be used to create a folder in the output folder\n",
        "        # it will also replace any [name] token in the rest of this config\n",
        "        'name': 'detail_slider_v1',\n",
        "        # folder will be created with name above in folder below\n",
        "        # it can be relative to the project root or absolute\n",
        "        'training_folder': \"output/LoRA\",\n",
        "        'device': 'cuda',  # cpu, cuda:0, etc\n",
        "        # for tensorboard logging, we will make a subfolder for this job\n",
        "        'log_dir': \"output/.tensorboard\",\n",
        "        # you can stack processes for other jobs, It is not tested with sliders though\n",
        "        # just use one for now\n",
        "        'process': [\n",
        "            {\n",
        "                'type': 'slider',  # tells runner to run the slider process\n",
        "                # network is the LoRA network for a slider, I recommend to leave this be\n",
        "                'network': {\n",
        "                    'type': \"lora\",\n",
        "                    # rank / dim of the network. Bigger is not always better. Especially for sliders. 8 is good\n",
        "                    'linear': 8,  # \"rank\" or \"dim\"\n",
        "                    'linear_alpha': 4,  # Do about half of rank \"alpha\"\n",
        "                    # 'conv': 4,  # for convolutional layers \"locon\"\n",
        "                    # 'conv_alpha': 4,  # Do about half of conv \"alpha\"\n",
        "                },\n",
        "                # training config\n",
        "                'train': {\n",
        "                    # this is also used in sampling. Stick with ddpm unless you know what you are doing\n",
        "                    'noise_scheduler': \"ddpm\",  # or \"ddpm\", \"lms\", \"euler_a\"\n",
        "                    # how many steps to train. More is not always better. I rarely go over 1000\n",
        "                    'steps': 100,\n",
        "                    # I have had good results with 4e-4 to 1e-4 at 500 steps\n",
        "                    'lr': 2e-4,\n",
        "                    # enables gradient checkpoint, saves vram, leave it on\n",
        "                    'gradient_checkpointing': True,\n",
        "                    # train the unet. I recommend leaving this true\n",
        "                    'train_unet': True,\n",
        "                    # train the text encoder. I don't recommend this unless you have a special use case\n",
        "                    # for sliders we are adjusting representation of the concept (unet),\n",
        "                    # not the description of it (text encoder)\n",
        "                    'train_text_encoder': False,\n",
        "\n",
        "                    # just leave unless you know what you are doing\n",
        "                    # also supports \"dadaptation\" but set lr to 1 if you use that,\n",
        "                    # but it learns too fast and I don't recommend it\n",
        "                    'optimizer': \"adamw\",\n",
        "                    # only constant for now\n",
        "                    'lr_scheduler': \"constant\",\n",
        "                    # we randomly denoise random num of steps form 1 to this number\n",
        "                    # while training. Just leave it\n",
        "                    'max_denoising_steps': 40,\n",
        "                    # works great at 1. I do 1 even with my 4090.\n",
        "                    # higher may not work right with newer single batch stacking code anyway\n",
        "                    'batch_size': 1,\n",
        "                    # bf16 works best if your GPU supports it (modern)\n",
        "                    'dtype': 'bf16',  # fp32, bf16, fp16\n",
        "                    # I don't recommend using unless you are trying to make a darker lora. Then do 0.1 MAX\n",
        "                    # although, the way we train sliders is comparative, so it probably won't work anyway\n",
        "                    'noise_offset': 0.0,\n",
        "                },\n",
        "\n",
        "                # the model to train the LoRA network on\n",
        "                'model': {\n",
        "                    # name_or_path can be a hugging face name, local path or url to model\n",
        "                    # on civit ai with or without modelVersionId. They will be cached in /model folder\n",
        "                    # epicRealisim v5\n",
        "                    'name_or_path': \"https://civitai.com/models/25694?modelVersionId=134065\",\n",
        "                    'is_v2': False,  # for v2 models\n",
        "                    'is_v_pred': False,  # for v-prediction models (most v2 models)\n",
        "                    # has some issues with the dual text encoder and the way we train sliders\n",
        "                    # it works bit weights need to probably be higher to see it.\n",
        "                    'is_xl': False,  # for SDXL models\n",
        "                },\n",
        "\n",
        "                # saving config\n",
        "                'save': {\n",
        "                    'dtype': 'float16',  # precision to save. I recommend float16\n",
        "                    'save_every': 50,  # save every this many steps\n",
        "                    # this will remove step counts more than this number\n",
        "                    # allows you to save more often in case of a crash without filling up your drive\n",
        "                    'max_step_saves_to_keep': 2,\n",
        "                },\n",
        "\n",
        "                # sampling config\n",
        "                'sample': {\n",
        "                    # must match train.noise_scheduler, this is not used here\n",
        "                    # but may be in future and in other processes\n",
        "                    'sampler': \"ddpm\",\n",
        "                    # sample every this many steps\n",
        "                    'sample_every': 20,\n",
        "                    # image size\n",
        "                    'width': 512,\n",
        "                    'height': 512,\n",
        "                    # prompts to use for sampling. Do as many as you want, but it slows down training\n",
        "                    # pick ones that will best represent the concept you are trying to adjust\n",
        "                    # allows some flags after the prompt\n",
        "                    #  --m [number]  # network multiplier. LoRA weight. -3 for the negative slide, 3 for the positive\n",
        "                    #      slide are good tests. will inherit sample.network_multiplier if not set\n",
        "                    #  --n [string]  # negative prompt, will inherit sample.neg if not set\n",
        "                    # Only 75 tokens allowed currently\n",
        "                    # I like to do a wide positive and negative spread so I can see a good range and stop\n",
        "                    # early if the network is braking down\n",
        "                    'prompts': [\n",
        "                        \"a woman in a coffee shop, black hat, blonde hair, blue jacket --m -5\",\n",
        "                        \"a woman in a coffee shop, black hat, blonde hair, blue jacket --m -3\",\n",
        "                        \"a woman in a coffee shop, black hat, blonde hair, blue jacket --m 3\",\n",
        "                        \"a woman in a coffee shop, black hat, blonde hair, blue jacket --m 5\",\n",
        "                        \"a golden retriever sitting on a leather couch, --m -5\",\n",
        "                        \"a golden retriever sitting on a leather couch --m -3\",\n",
        "                        \"a golden retriever sitting on a leather couch --m 3\",\n",
        "                        \"a golden retriever sitting on a leather couch --m 5\",\n",
        "                        \"a man with a beard and red flannel shirt, wearing vr goggles, walking into traffic --m -5\",\n",
        "                        \"a man with a beard and red flannel shirt, wearing vr goggles, walking into traffic --m -3\",\n",
        "                        \"a man with a beard and red flannel shirt, wearing vr goggles, walking into traffic --m 3\",\n",
        "                        \"a man with a beard and red flannel shirt, wearing vr goggles, walking into traffic --m 5\",\n",
        "                    ],\n",
        "                    # negative prompt used on all prompts above as default if they don't have one\n",
        "                    'neg': \"cartoon, fake, drawing, illustration, cgi, animated, anime, monochrome\",\n",
        "                    # seed for sampling. 42 is the answer for everything\n",
        "                    'seed': 42,\n",
        "                    # walks the seed so s1 is 42, s2 is 43, s3 is 44, etc\n",
        "                    # will start over on next sample_every so s1 is always seed\n",
        "                    # works well if you use same prompt but want different results\n",
        "                    'walk_seed': False,\n",
        "                    # cfg scale (4 to 10 is good)\n",
        "                    'guidance_scale': 7,\n",
        "                    # sampler steps (20 to 30 is good)\n",
        "                    'sample_steps': 20,\n",
        "                    # default network multiplier for all prompts\n",
        "                    # since we are training a slider, I recommend overriding this with --m [number]\n",
        "                    # in the prompts above to get both sides of the slider\n",
        "                    'network_multiplier': 1.0,\n",
        "                },\n",
        "\n",
        "                # logging information\n",
        "                'logging': {\n",
        "                    'log_every': 10,  # log every this many steps\n",
        "                    'use_wandb': False,  # not supported yet\n",
        "                    'verbose': False,  # probably done need unless you are debugging\n",
        "                },\n",
        "\n",
        "                # slider training config, best for last\n",
        "                'slider': {\n",
        "                    # resolutions to train on. [ width, height ]. This is less important for sliders\n",
        "                    # as we are not teaching the model anything it doesn't already know\n",
        "                    # but must be a size it understands [ 512, 512 ] for sd_v1.5  and [ 768, 768 ] for sd_v2.1\n",
        "                    # and [ 1024, 1024 ] for sd_xl\n",
        "                    # you can do as many as you want here\n",
        "                    'resolutions': [\n",
        "                        [512, 512],\n",
        "                        # [ 512, 768 ]\n",
        "                        # [ 768, 768 ]\n",
        "                    ],\n",
        "                    # slider training uses 4 combined steps for a single round. This will do it in one gradient\n",
        "                    # step. It is highly optimized and shouldn't take anymore vram than doing without it,\n",
        "                    # since we break down batches for gradient accumulation now. so just leave it on.\n",
        "                    'batch_full_slide': True,\n",
        "                    # These are the concepts to train on. You can do as many as you want here,\n",
        "                    # but they can conflict outweigh each other. Other than experimenting, I recommend\n",
        "                    # just doing one for good results\n",
        "                    'targets': [\n",
        "                        # target_class is the base concept we are adjusting the representation of\n",
        "                        # for example, if we are adjusting the representation of a person, we would use \"person\"\n",
        "                        # if we are adjusting the representation of a cat, we would use \"cat\" It is not\n",
        "                        # a keyword necessarily but what the model understands the concept to represent.\n",
        "                        # \"person\" will affect men, women, children, etc but will not affect cats, dogs, etc\n",
        "                        # it is the models base general understanding of the concept and everything it represents\n",
        "                        # you can leave it blank to affect everything. In this example, we are adjusting\n",
        "                        # detail, so we will leave it blank to affect everything\n",
        "                        {\n",
        "                            'target_class': \"\",\n",
        "                            # positive is the prompt for the positive side of the slider.\n",
        "                            # It is the concept that will be excited and amplified in the model when we slide the slider\n",
        "                            # to the positive side and forgotten / inverted when we slide\n",
        "                            # the slider to the negative side. It is generally best to include the target_class in\n",
        "                            # the prompt. You want it to be the extreme of what you want to train on. For example,\n",
        "                            # if you want to train on fat people, you would use \"an extremely fat, morbidly obese person\"\n",
        "                            # as the prompt. Not just \"fat person\"\n",
        "                            # max 75 tokens for now\n",
        "                            'positive': \"high detail, 8k, intricate, detailed, high resolution, high res, high quality\",\n",
        "                            # negative is the prompt for the negative side of the slider and works the same as positive\n",
        "                            # it does not necessarily work the same as a negative prompt when generating images\n",
        "                            # these need to be polar opposites.\n",
        "                            # max 76 tokens for now\n",
        "                            'negative': \"blurry, boring, fuzzy, low detail, low resolution, low res, low quality\",\n",
        "                            # the loss for this target is multiplied by this number.\n",
        "                            # if you are doing more than one target it may be good to set less important ones\n",
        "                            # to a lower number like 0.1 so they don't outweigh the primary target\n",
        "                            'weight': 1.0,\n",
        "                        },\n",
        "                    ],\n",
        "                },\n",
        "            },\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    # You can put any information you want here, and it will be saved in the model.\n",
        "    # The below is an example, but you can put your grocery list in it if you want.\n",
        "    # It is saved in the model so be aware of that. The software will include this\n",
        "    # plus some other information for you automatically\n",
        "    'meta': {\n",
        "        # [name] gets replaced with the name above\n",
        "        'name': \"[name]\",\n",
        "        'version': '1.0',\n",
        "        # 'creator': {\n",
        "        #     'name': 'your name',\n",
        "        #     'email': 'your@gmail.com',\n",
        "        #     'website': 'https://your.website'\n",
        "        # }\n",
        "    }\n",
        "})\n"
      ],
      "metadata": {
        "id": "_t28QURYjRQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run it\n",
        "\n",
        "Below does all the magic. Check your folders to the left. Items will be in output/LoRA/your_name_v1 In the samples folder, there are preiodic sampled. This doesnt work great with colab. Ill update soon."
      ],
      "metadata": {
        "id": "h6F1FlM2Wb3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_job(job_to_run)\n"
      ],
      "metadata": {
        "id": "HkajwI8gteOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "007edb7a"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/ai-toolkit')\n",
        "from toolkit.job import run_job\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "!pip install numpy==1.23.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Done\n",
        "\n",
        "Check your ourput dir and get your slider\n"
      ],
      "metadata": {
        "id": "Hblgb5uwW5SD"
      }
    }
  ]
}